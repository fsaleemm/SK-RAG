{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to implement RAG Pattern using Semantic Kernel and Azure Cognitive Search\n",
    "**NOTE**: This notebook requires that a search index exists with semantic search and vector index enabled.\n",
    "\n",
    "Follow the steps in the [Notebook](https://github.com/fsaleemm/cognitive-search-vector-pr/blob/main/demo-python/code/azure-search-vector-python-sample.ipynb) to create the vector index with semantic search enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a virtual environment\n",
    "#os.system('python3 -m venv env')\n",
    "\n",
    "# Activate the virtual environment\n",
    "os.system('source env/bin/activate')\n",
    "\n",
    "# Install dependencies\n",
    "#os.system('pip install -r requirements.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install python-dotenv==1.0.0\n",
    "!python -m pip install --upgrade semantic-kernel\n",
    "!python -m pip install azure-search-documents==11.4.0b9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "if not load_dotenv(): raise Exception(\".env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Semantic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x29ab1046010>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_text_embedding_generation_service(\n",
    "    \"ada\",\n",
    "    AzureTextEmbedding(\n",
    "        os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "        os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "kernel.add_chat_service(\n",
    "    \"chat\",\n",
    "    AzureChatCompletion(\n",
    "        os.getenv(\"AZURE_OPENAI_CHAT_MODEL\"),\n",
    "        os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the intent of the question being asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"What is the moonthly fare from grand central to fordham?\"\n",
    "#question = \"What is the off peak child one way fare from grand central to fordham?\"\n",
    "#question = \"What is the total fare from grand central to fordham if traveling peak time as senior citizen?\"\n",
    "#question = \"What is the total fare from grand central to fordham if traveling off peak time as disabled person?\"\n",
    "#question = \"What is the total fare for ten trips from grand central to fordham if traveling off peak time as disabled person?\"\n",
    "#question = \"What is the moonthly fare from fordham to grand central?\"\n",
    "\n",
    "question = \"What is the total fare from grand central to fordham if traveling peak time with 1 adult and 2 children?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking for the total fare from Grand Central to Fordham during peak time with 1 adult and 2 children.\n"
     ]
    }
   ],
   "source": [
    "#intent detection\n",
    "\n",
    "from semantic_kernel import PromptTemplate, PromptTemplateConfig, SemanticFunctionConfig\n",
    "\n",
    "\n",
    "prompt = \"\"\"Bot: How can I help you?\n",
    "User: {{$input}}\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "The intent of the user: \"\"\"\n",
    "\n",
    "prompt_config = PromptTemplateConfig(\n",
    "    description=\"Gets the intent of the user.\",\n",
    "    type=\"completion\",\n",
    "    completion=PromptTemplateConfig.CompletionConfig(0.0, 0.0, 0.0, 0.0, 500),\n",
    "    input=PromptTemplateConfig.InputConfig(\n",
    "        parameters=[\n",
    "            PromptTemplateConfig.InputParameter(\n",
    "                name=\"input\", description=\"The user's request.\", default_value=\"\"\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Create the SemanticFunctionConfig object\n",
    "prompt_template = PromptTemplate(\n",
    "    template=prompt,\n",
    "    template_engine=kernel.prompt_template_engine,\n",
    "    prompt_config=prompt_config,\n",
    ")\n",
    "\n",
    "function_config = SemanticFunctionConfig(prompt_config, prompt_template)\n",
    "\n",
    "get_intent = kernel.register_semantic_function(\n",
    "    skill_name=\"OrchestratorPlugin\",\n",
    "    function_name=\"GetIntent\",\n",
    "    function_config=function_config,\n",
    ")\n",
    "\n",
    "result_intent = await kernel.run_async(\n",
    "    get_intent,\n",
    "    input_str=question,\n",
    ")\n",
    "\n",
    "print(result_intent.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get relevant data from the ACS index using hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"from-stations\": [\"Grand Central/Harlem-125th Street\"],\n",
      "    \"zoneNumber\": \"2\",\n",
      "    \"to-stations\": [\"Fordham\"],\n",
      "    \"fares\": {\n",
      "        \"adult\": {\n",
      "            \"peak\": {\n",
      "                \"monthly\": 199.75,\n",
      "                \"weekly\": 71.00,\n",
      "                \"10-trip\": 100.00,\n",
      "                \"one-way\": 10.00,\n",
      "                \"onboard-fares\": 16.00,\n",
      "                \"LIRR-combo\": 15.50\n",
      "            },\n",
      "            \"off-peak\": {\n",
      "                \"monthly\": 199.75,\n",
      "                \"weekly\": 71.00,\n",
      "                \"10-trip\": 63.75,\n",
      "                \"one-way\": 7.50,\n",
      "                \"onboard-fares\": 14.00,\n",
      "                \"LIRR-combo\": 15.50\n",
      "            }\n",
      "        },\n",
      "        \"senior-Disabled-Medicare\": {\n",
      "            \"peak\": {\n",
      "                \"10-trip\": 100.00,\n",
      "                \"one-way\": 10.00\n",
      "            },\n",
      "            \"offPeak\": {\n",
      "                \"10-trip\": 50.00,\n",
      "                \"one-way\": 5.00\n",
      "            }\n",
      "        },\n",
      "        \"child\": {\n",
      "\t\t\t\"peak\": {\n",
      "                \"family-fare\": 1.00,\n",
      "                \"one-way\": 5.00,\n",
      "\t\t\t\t\"onboard-fares\": 11.00\n",
      "            },\n",
      "            \"offPeak\": {\n",
      "                \"family-fare\": 1.00,\n",
      "                \"one-way\": 5.00,\n",
      "\t\t\t\t\"onboard-fares\": 10.00\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "} {\n",
      "    \"from-stations\": [\"Grand Central/Harlem-125th Street\"],\n",
      "    \"zoneNumber\": \"12\",\n",
      "    \"to-stations\": [\"Mt. Vernon East\", \"Pelham\", \"New Rochelle\"],\n",
      "    \"fares\": {\n",
      "        \"adult\": {\n",
      "            \"peak\": {\n",
      "                \"monthly\": 233.00,\n",
      "                \"weekly\": 83.00,\n",
      "                \"10-trip\": 117.50,\n",
      "                \"one-way\": 11.75,\n",
      "                \"onboard-fares\": 18.00,\n",
      "                \"LIRR-combo\": 16.75\n",
      "            },\n",
      "            \"off-peak\": {\n",
      "                \"monthly\": 233.00,\n",
      "                \"weekly\": 83.00,\n",
      "                \"10-trip\": 74.50,\n",
      "                \"one-way\": 8.75,\n",
      "                \"onboard-fares\": 15.00,\n",
      "                \"LIRR-combo\": 16.75\n",
      "            }\n",
      "        },\n",
      "        \"senior-Disabled-Medicare\": {\n",
      "            \"peak\": {\n",
      "                \"10-trip\": 117.50,\n",
      "                \"one-way\": 11.75\n",
      "            },\n",
      "            \"offPeak\": {\n",
      "                \"10-trip\": 57.50,\n",
      "                \"one-way\": 5.75\n",
      "            }\n",
      "        },\n",
      "        \"child\": {\n",
      "\t\t\t\"peak\": {\n",
      "                \"family-fare\": 1.00,\n",
      "                \"one-way\": $5.75,\n",
      "\t\t\t\t\"onboard-fares\": 12.00\n",
      "            },\n",
      "            \"offPeak\": {\n",
      "                \"family-fare\": 1.00,\n",
      "                \"one-way\": 4.50,\n",
      "\t\t\t\t\"onboard-fares\": 11.00\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#get relevant data for context\n",
    "filenames = ['data/zone2.txt', 'data/zone12.txt']\n",
    "\n",
    "contents = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        contents.append(f.read().strip())\n",
    "\n",
    "results = ' '.join(contents)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: What is the total fare from grand central to fordham if traveling peak time with 1 adult and 2 children?\n",
      "Optimized Question: Asking for the total fare from Grand Central to Fordham during peak time with 1 adult and 2 children.\n",
      "---\n",
      "Answer: The total fare from Grand Central to Fordham during peak time with 1 adult and 2 children is $21.00.\n",
      "\n",
      "Explanation: The fare for 1 adult during peak time is $10.00 and the fare for 2 children during peak time is $1.00. Adding these fares together gives a total of $21.00.\n"
     ]
    }
   ],
   "source": [
    "#Summarize\n",
    "\n",
    "import semantic_kernel\n",
    "\n",
    "\n",
    "sprompt = \"\"\"\n",
    "Considering these facts\n",
    "\n",
    "Facts: {{$results}}\n",
    "\n",
    "Question: {{$input}}\n",
    "\n",
    "Provide a concise answer ('Answer: ') and a separate detailed explanation ('Explanation: '), in two lines.\n",
    "\"\"\"\n",
    "\n",
    "sprompt_config = PromptTemplateConfig(\n",
    "    description=\"Gets the intent of the user.\",\n",
    "    type=\"completion\",\n",
    "    completion=PromptTemplateConfig.CompletionConfig(0.5, 0.0, 0.0, 0.0, 1024),\n",
    "    input=PromptTemplateConfig.InputConfig(\n",
    "        parameters=[\n",
    "            PromptTemplateConfig.InputParameter(\n",
    "                name=\"input\", description=\"The user's request.\", default_value=\"\"\n",
    "            ),\n",
    "            PromptTemplateConfig.InputParameter(\n",
    "                name=\"results\", description=\"The result from grounding data\", default_value=\"\"\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Create the SemanticFunctionConfig object\n",
    "sprompt_template = PromptTemplate(\n",
    "    template=sprompt,\n",
    "    template_engine=kernel.prompt_template_engine,\n",
    "    prompt_config=sprompt_config,\n",
    ")\n",
    "\n",
    "sfunction_config = SemanticFunctionConfig(sprompt_config, sprompt_template)\n",
    "\n",
    "get_summary = kernel.register_semantic_function(\n",
    "    skill_name=\"OrchestratorPlugin\",\n",
    "    function_name=\"GetSummary\",\n",
    "    function_config=sfunction_config,\n",
    ")\n",
    "\n",
    "variables = semantic_kernel.ContextVariables()\n",
    "variables[\"input\"] = result_intent.result #question #result_intent.result\n",
    "variables[\"results\"] = results\n",
    "\n",
    "result_summary = await kernel.run_async(\n",
    "    get_summary,\n",
    "    input_vars=variables\n",
    ")\n",
    "\n",
    "print(f\"Original Question: {question}\")\n",
    "print(f\"Optimized Question: {result_intent}\")\n",
    "print(\"---\")\n",
    "print(result_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
