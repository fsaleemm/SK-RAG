{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use Semantic Kernel Memory with Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "!python -m pip install python-dotenv==1.0.0\n",
    "!python -m pip install --upgrade semantic-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "if not load_dotenv(): raise Exception(\".env file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Semantic Kernel and Azure Cognitive Search memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Semantic Kernel\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from semantic_kernel.connectors.memory.azure_cognitive_search import AzureCognitiveSearchMemoryStore\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_text_embedding_generation_service(\n",
    "    \"ada\",\n",
    "    AzureTextEmbedding(\n",
    "        os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\"),\n",
    "        os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "kernel.add_chat_service(\n",
    "    \"chat\",\n",
    "    AzureChatCompletion(\n",
    "        os.getenv(\"AZURE_OPENAI_CHAT_MODEL\"),\n",
    "        os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "kernel.register_memory_store(\n",
    "    memory_store=AzureCognitiveSearchMemoryStore(\n",
    "        1536, os.getenv(\"AZURE_SEARCH_ENDPOINT\"), os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the Azure Cognitive Search vector store with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index data - only need to run once\n",
    "\n",
    "with open('data/text-sample.json', 'r', encoding='utf-8') as file:\n",
    "    input_data = json.load(file)\n",
    "\n",
    "i=0\n",
    "for item in input_data:\n",
    "    await kernel.memory.save_information_async(\n",
    "        \"skidx1\", id=\"info\"+str(i), text=item['content']\n",
    "    )\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the intent of the question being asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What services are best for asynchornous communications?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inquiring about asynchronous communication services\n"
     ]
    }
   ],
   "source": [
    "#intent detection\n",
    "\n",
    "from semantic_kernel import PromptTemplate, PromptTemplateConfig, SemanticFunctionConfig\n",
    "\n",
    "\n",
    "prompt = \"\"\"Bot: How can I help you?\n",
    "User: {{$input}}\n",
    "\n",
    "---------------------------------------------\n",
    "\n",
    "The intent of the user in 5 words or less: \"\"\"\n",
    "\n",
    "prompt_config = PromptTemplateConfig(\n",
    "    description=\"Gets the intent of the user.\",\n",
    "    type=\"completion\",\n",
    "    completion=PromptTemplateConfig.CompletionConfig(0.0, 0.0, 0.0, 0.0, 500),\n",
    "    input=PromptTemplateConfig.InputConfig(\n",
    "        parameters=[\n",
    "            PromptTemplateConfig.InputParameter(\n",
    "                name=\"input\", description=\"The user's request.\", default_value=\"\"\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Create the SemanticFunctionConfig object\n",
    "prompt_template = PromptTemplate(\n",
    "    template=prompt,\n",
    "    template_engine=kernel.prompt_template_engine,\n",
    "    prompt_config=prompt_config,\n",
    ")\n",
    "\n",
    "function_config = SemanticFunctionConfig(prompt_config, prompt_template)\n",
    "\n",
    "get_intent = kernel.register_semantic_function(\n",
    "    skill_name=\"OrchestratorPlugin\",\n",
    "    function_name=\"GetIntent\",\n",
    "    function_config=function_config,\n",
    ")\n",
    "\n",
    "result_intent = await kernel.run_async(\n",
    "    get_intent,\n",
    "    input_str=question,\n",
    ")\n",
    "\n",
    "print(result_intent.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and Summarize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: What services are best for asynchornous communications?\n",
      "Optimized Question: Inquiring about asynchronous communication services\n",
      "---\n",
      "Answer: Azure Logic Apps and Azure Bot Service.\n",
      "\n",
      "Explanation: Azure Logic Apps allows you to create and run workflows that integrate with various services and data sources, enabling asynchronous communication. Azure Bot Service, with its multi-channel support, can also facilitate asynchronous communication through chatbots.\n"
     ]
    }
   ],
   "source": [
    "# Create Semantic Function\n",
    "\n",
    "from semantic_kernel.core_skills import TextMemorySkill\n",
    "\n",
    "kernel.import_skill(TextMemorySkill())\n",
    "\n",
    "sk_prompt = \"\"\"\n",
    "Considering these facts\n",
    "\n",
    "Facts: {{recall '{{$intent}}'}}\n",
    "\n",
    "Question: {{$input}}\n",
    "\n",
    "Provide a concise answer ('Answer: ') and a separate explanation ('Explanation: '), in two lines.\n",
    "\"\"\"\n",
    "\n",
    "sk_function = kernel.create_semantic_function(prompt_template=sk_prompt, max_tokens=1024)\n",
    "\n",
    "# Set Context and execute\n",
    "import semantic_kernel as sk\n",
    "\n",
    "context= kernel.create_new_context()\n",
    "context[TextMemorySkill.COLLECTION_PARAM] = \"skidx1\";\n",
    "context[TextMemorySkill.LIMIT_PARAM] = \"3\";\n",
    "\n",
    "variables = sk.ContextVariables()\n",
    "variables[\"input\"] = question\n",
    "variables[\"intent\"] = result_intent.result\n",
    "\n",
    "\n",
    "result = await sk_function.invoke_async(input=question, context=context, variables=variables)\n",
    "\n",
    "print(f\"Original Question: {question}\")\n",
    "print(f\"Optimized Question: {result_intent}\")\n",
    "print(\"---\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv-3.11.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
